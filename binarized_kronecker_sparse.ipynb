{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import pandas as pd \n",
    "import torch as torch \n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import dataset_utils\n",
    "import torch.nn.functional as F\n",
    "import torchvision.models as models\n",
    "from pytorch_metric_learning import distances, losses, miners, reducers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def binarize_hard(x):\n",
    "    return torch.where(x > 0, 1.0, -1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def activation_binarize(a):\n",
    "    a = torch.where(a<-1,-1,a)\n",
    "    a = torch.where(a>1,1,a)\n",
    "    mask1 = (a >= -1) & (a < 0)\n",
    "    a[mask1] = 2 * a[mask1] + a[mask1]*a[mask1]\n",
    "    #a[mask1] = 0\n",
    "    mask2 = (a >= 0) & (a < 1)\n",
    "    a[mask2] = 2 * a[mask2] - a[mask2]*a[mask2]\n",
    "    #a = torch.where((a >= -1) & (a < 0),2*a + torch.pow(a,2) )\n",
    "    #a = torch.where((a >= 0) & (a < 1), 2*a- torch.pow(a,2))\n",
    "    #    a [a < -1] = -1\n",
    "    #    a [a > 1]   =  1\n",
    "    #    a [(a >= -1) & (a < 0)] = 2*a[(a >= -1) & (a < 0)] + torch.pow(a [(a >= -1) & (a < 0)],2)\n",
    "    #    a [(a >= 0) & (a < 1)] = 2*a[(a >= 0) & (a < 1)] - torch.pow(a [(a >= 0) & (a < 1)],2)\n",
    "    return a\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_sparse_encode(w, sparsity):\n",
    "    # Flatten the weight tensor\n",
    "    #w_flat = w.reshape(-1)\n",
    "    #print(w.size())\n",
    "\n",
    "    # Calculate the threshold value for sparsity\n",
    "    threshold = torch.kthvalue(torch.abs(w), int(sparsity * w.numel())).values\n",
    "\n",
    "    # Apply binary sparse encoding\n",
    "    w_sparse = torch.where(torch.abs(w) < threshold, torch.tensor(0.), activation_binarize(w))\n",
    "\n",
    "    return w_sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Set the tensor size and block size\n",
    "def obtain_sparsity(w,block_size,sparsity):\n",
    "    tensor_size = w.shape[1]\n",
    "    #print(tensor_size)\n",
    "    num_rows = w.shape[0]\n",
    "    block_size = block_size\n",
    "\n",
    "    # Compute the number of blocks\n",
    "    num_blocks = tensor_size // block_size\n",
    "    #print(num_blocks)\n",
    "    # Create a sparse binary code for each block\n",
    "    blocks = []\n",
    "    for j in range(num_rows):\n",
    "        for i in range(num_blocks):\n",
    "            # Create a block of zeros\n",
    "            #print(\"i\",i)\n",
    "            #print(\"j\",j)\n",
    "            block = w[j,i*block_size:(i+1)*block_size].data.clone()\n",
    "            #print(block)\n",
    "            block = binary_sparse_encode(block, sparsity) \n",
    "            # Add the block to the list of blocks\n",
    "            w[j,i*block_size:(i+1)*block_size] = block.clone()\n",
    "            #blocks.append(block)\n",
    "            #print(block)\n",
    "    # Concatenate the blocks to form the sparse binary tensor\n",
    "    sparse_binary_tensor = w.data.clone()\n",
    "    # Print the resulting tensor\n",
    "    return sparse_binary_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.3587, -1.2301,  1.4772,  1.5873, -0.4807,  1.7282, -0.7645, -1.5076,\n",
      "          0.4562,  0.0380],\n",
      "        [ 0.8640,  1.1911, -0.7465,  0.3423,  0.6491, -1.5532,  0.5984,  1.4406,\n",
      "          1.6068,  0.3420],\n",
      "        [-0.3904,  0.8215,  1.3790, -1.2059, -1.6270, -0.2218, -2.0822, -1.4266,\n",
      "         -0.3863, -0.5727],\n",
      "        [ 0.5741, -1.8381,  0.4561,  0.6806,  1.0074, -0.1781,  0.0094, -1.0920,\n",
      "         -0.8579,  0.5511],\n",
      "        [ 2.0721, -1.4283,  1.1602,  0.1058,  2.3922, -0.7764, -1.7538, -0.6910,\n",
      "          0.2333,  0.6688]])\n",
      "shape of sparse_a torch.Size([5, 10])\n",
      "tensor([[ 0.0000,  0.0000,  1.0000,  1.0000,  0.0000,  1.0000,  0.0000, -1.0000,\n",
      "          0.0000,  0.0000],\n",
      "        [ 0.9815,  1.0000,  0.0000,  0.0000,  0.0000, -1.0000,  0.0000,  0.0000,\n",
      "          1.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  1.0000,  0.0000, -1.0000,  0.0000, -1.0000, -1.0000,\n",
      "          0.0000,  0.0000],\n",
      "        [ 0.0000, -1.0000,  0.0000,  0.0000,  1.0000,  0.0000,  0.0000, -1.0000,\n",
      "         -0.9798,  0.0000],\n",
      "        [ 1.0000,  0.0000,  0.0000,  0.0000,  1.0000, -0.9500, -1.0000,  0.0000,\n",
      "          0.0000,  0.0000]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "a = torch.randn(5,10)\n",
    "print(a)\n",
    "sparse_a = obtain_sparsity(a,5,0.8)\n",
    "print(f\"shape of sparse_a\",sparse_a.shape)\n",
    "print(sparse_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reference code\n",
    "class BinaryModel(nn.Module):\n",
    "    def __init__(self, dim, D, num_classes, enc_type='RP', binary=True, device='cpu', sparsity = 0.6, block_size =10, kargs=None):\n",
    "        super(BinaryModel, self).__init__()\n",
    "        self.enc_type, self.binary = enc_type, binary\t\n",
    "        self.device = device\n",
    "        self.sparsity = sparsity\n",
    "        self.block_size = block_size\n",
    "        if enc_type in ['RP', 'RP-COS']:\n",
    "            self.rp_layer = nn.Linear(dim, D).to(device)\n",
    "            self.class_hvs = torch.zeros(num_classes, D).float().to(device)\n",
    "            self.class_hvs_nb = torch.zeros(num_classes, D).float().to(device)\n",
    "        else:\n",
    "            pass\n",
    "    #hard sigmoid    \n",
    "    def weight_binarize(self, W):\n",
    "       W = torch.where(W<-1,-1,W)\n",
    "       W = torch.where(W>1,1,W)\n",
    "       mask1 = (W >= -1) & (W < 0)\n",
    "       W[mask1] = 2 * W[mask1] + W[mask1]*W[mask1]\n",
    "       mask2 = (W >= 0) & (W < 1)\n",
    "       W[mask2] = 2 * W[mask2] - W[mask2]*W[mask2]\n",
    "       # W[W > 1] = 1\n",
    "       return W\n",
    "    #using Bi-Real Approximation     \n",
    "    def activation_binarize(self,a):\n",
    "       a = torch.where(a<-1,-1,a)\n",
    "       a = torch.where(a>1,1,a)\n",
    "       mask1 = (a >= -1) & (a < 0)\n",
    "       a[mask1] = 2 * a[mask1] + a[mask1]*a[mask1]\n",
    "       #a[mask1] = 0\n",
    "       mask2 = (a >= 0) & (a < 1)\n",
    "       a[mask2] = 2 * a[mask2] - a[mask2]*a[mask2]\n",
    "       #a = torch.where((a >= -1) & (a < 0),2*a + torch.pow(a,2) )\n",
    "       #a = torch.where((a >= 0) & (a < 1), 2*a- torch.pow(a,2))\n",
    "    #    a [a < -1] = -1\n",
    "    #    a [a > 1]   =  1\n",
    "    #    a [(a >= -1) & (a < 0)] = 2*a[(a >= -1) & (a < 0)] + torch.pow(a [(a >= -1) & (a < 0)],2)\n",
    "    #    a [(a >= 0) & (a < 1)] = 2*a[(a >= 0) & (a < 1)] - torch.pow(a [(a >= 0) & (a < 1)],2)\n",
    "       return a\n",
    "\n",
    "    def encoding(self, x):\n",
    "        if self.enc_type == 'RP':\n",
    "            #x = self.activation_binarize(x) \n",
    "            #need not binarize the inputs \n",
    "            #progressively binarize the inputs, after training the weights\n",
    "            #add some print statements and check \n",
    "            #print(\"The value of weights, before binarization\")\n",
    "            #print(self.rp_layer.weight.data)\n",
    "            #comment\n",
    "            #do it with masking\n",
    "            weights = self.rp_layer.weight.data.clone()\n",
    "            weights_bin = self.weight_binarize(weights)\n",
    "            #self.rp_layer.weight.data = weights_bin.clone() \n",
    "            weight_sparse = obtain_sparsity(weights_bin, self.block_size,self.sparsity)\n",
    "            self.rp_layer.weight.data = weight_sparse.clone()\n",
    "            out = self.rp_layer(x)\n",
    "            #print(\"The value of weights, after binarization\")\n",
    "            #print(self.rp_layer.weight.data)\n",
    "        else:\n",
    "                pass\n",
    "        \n",
    "        return self.activation_binarize(out) if self.binary else out\n",
    "    \n",
    "    #Forward Function\n",
    "    def forward(self, x, embedding=False):\n",
    "        out = self.encoding(x)\n",
    "        #print(\"shape of weight\",self.model.rp_layer.weight.shape)\n",
    "        if embedding:\n",
    "            out = out\n",
    "        else:\n",
    "            out = self.similarity(class_hvs=binarize_hard(self.class_hvs), enc_hv=out)   \n",
    "        return out\n",
    "    \n",
    "    def init_class(self, x_train, labels_train):\n",
    "        out = self.encoding(x_train)\n",
    "        for i in range(x_train.size()[0]):\n",
    "            self.class_hvs[labels_train[i]] += out[i]\n",
    "\n",
    "        self.class_hvs = binarize_hard(self.class_hvs)\n",
    "        \n",
    "    def HD_train_step(self, x_train, y_train, lr=1.0):\n",
    "        shuffle_idx = torch.randperm(x_train.size()[0])\n",
    "        x_train = x_train[shuffle_idx]\n",
    "        train_labels = y_train[shuffle_idx]\n",
    "        l= list(self.rp_layer.parameters())\n",
    "        enc_hvs = binarize_hard(self.encoding(x_train))\n",
    "        for i in range(enc_hvs.size()[0]):\n",
    "            sims = self.similarity(self.class_hvs, enc_hvs[i].unsqueeze(dim=0))\n",
    "            predict = torch.argmax(sims, dim=1)\n",
    "            \n",
    "            if predict != train_labels[i]:\n",
    "                self.class_hvs_nb[predict] -= lr * enc_hvs[i]\n",
    "                self.class_hvs_nb[train_labels[i]] += lr * enc_hvs[i]\n",
    "            \n",
    "            self.class_hvs.data = binarize_hard(self.class_hvs_nb)\n",
    "    \n",
    "    def similarity(self, class_hvs, enc_hv):\n",
    "\t    return torch.matmul(enc_hv, class_hvs.t())/class_hvs.size()[1]\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "nFeatures, nClasses, x_train, y_train, x_test, y_test, train_loader, test_loader\\\n",
    "        = dataset_utils.load_dataset('mnist', 256, \"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, Subset\n",
    "from torchvision import datasets, transforms\n",
    "num_samples = 1000\n",
    "train_loader_truncated = Subset(train_loader.dataset, range(num_samples))\n",
    "train_loader_truncated = DataLoader(train_loader_truncated, batch_size=256, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.utils.prune as prune\n",
    "model = BinaryModel(dim = nFeatures, D=4000, num_classes=nClasses, enc_type='RP', device=\"cpu\", sparsity = 0.8, block_size=50)\n",
    "#prune.ln_structured(model.rp_layer, name='weight', amount=0.8, dim=0, n=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.01\n",
    "distance = distances.CosineSimilarity()\n",
    "reducer = reducers.ThresholdReducer(low=0.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def HD_test(model, x_test, y_test):\n",
    "\tout = model(x_test, embedding=False)\n",
    "\tpreds = torch.argmax(out, dim=-1)\n",
    "\tacc = torch.mean((preds==y_test).float())\t\n",
    "\treturn acc\n",
    "\n",
    "def get_Hamming_margin(model, x_test, y_test=None):\n",
    "\tdef Hamming_distance(a, b):\n",
    "\t\tD = a.size()[1]\n",
    "\t\treturn (D - a @ b.T)/2\n",
    "\n",
    "\t# Compute mean Hamming distance between class HVS\n",
    "\tclass_hvs = binarize_hard(model.class_hvs.data)\n",
    "\tclass_Hamming_distance = Hamming_distance(class_hvs, class_hvs)\n",
    "\tmean_class_Hamming_distance = torch.mean(class_Hamming_distance).item()\n",
    "\t\n",
    "\n",
    "\t# Compute test samples' Hamming distance\n",
    "\ttest_enc_hvs = binarize_hard(model(x_test, True)) \n",
    "\ttest_Hamming_dist = Hamming_distance(test_enc_hvs, class_hvs)\n",
    "\n",
    "\tsorted_test_Hamming_distance, _ = torch.sort(test_Hamming_dist, dim=-1, descending=False)\n",
    "\ttest_enc_hvs_Hamming_margin = (sorted_test_Hamming_distance[:,1:]-sorted_test_Hamming_distance[:,0].unsqueeze(dim=1)).mean(dim=1).cpu()\n",
    "\tmean_test_Hamming_margin = torch.mean(test_enc_hvs_Hamming_margin).item()\n",
    "\n",
    "\tres_dict = {\n",
    "\t\t\"avg_class_Hamming_dist\": mean_class_Hamming_distance,\n",
    "\t\t\"avg_test_Hamming_margin\": mean_test_Hamming_margin\n",
    "\t}\n",
    "\treturn mean_test_Hamming_margin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "num_metric_epochs = 2\n",
    "device = \"cpu\"\n",
    "accuracies = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "accuracies.append(HD_test(model, x_test, y_test).item())\n",
    "margins = []\n",
    "margins.append(get_Hamming_margin(model, x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#loss_class = CustomLoss(model, distance = distance,reducer = reducer,dimension = 1000, segment_size = 100, sparsity_factor= 80, penalty_factor = 0.5)\n",
    "#loss_func = loss_class.loss_calc()\n",
    "loss_func = losses.TripletMarginLoss(margin=0.2, distance=distance, reducer=reducer)\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=0) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model.class_hvs = nn.parameter.Parameter(data=model.class_hvs)\n",
    "mining_func = miners.TripletMarginMiner(\n",
    "    margin=0.2, distance=distance, type_of_triplets=\"semihard\", )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metric_train(model, mining_func, device, train_loader, optimizer, epoch,segment_length, zeroes):\n",
    "    model.train()\n",
    "    for batch_idx, (data, labels) in enumerate(train_loader):\n",
    "        data, labels = data.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        embeddings = model(data.reshape(data.size()[0],-1))\n",
    "        indices_tuple = mining_func(embeddings, labels)\n",
    "        loss = loss_func(embeddings,labels,indices_tuple)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Triplet Loss\n",
      "Epoch 1\n",
      "Epoch 2\n"
     ]
    }
   ],
   "source": [
    "### pytorch-metric-learning using Triplet margin loss ###\n",
    "print(\"Triplet Loss\")\n",
    "for epoch_i in range(1, num_metric_epochs + 1):\n",
    "    metric_train(model, mining_func, device, train_loader_truncated, optimizer, epoch_i,segment_length=50, zeroes=25)\n",
    "    #print(\"finished metric train\")\n",
    "    accuracies.append(HD_test(model, x_test, y_test).item())\n",
    "    margins.append(get_Hamming_margin(model, x_test, y_test))\n",
    "    print(\"Epoch\",epoch_i)\n",
    "    #print(\"Accuracy\",HD_test(model, x_test, y_test).item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained Weights\n",
      "tensor([[ 1.,  0.,  0.,  ...,  1.,  1.,  1.],\n",
      "        [ 0.,  0.,  1.,  ..., -1.,  1.,  1.],\n",
      "        [ 0.,  1., -1.,  ...,  1., -1., -1.],\n",
      "        ...,\n",
      "        [ 0.,  0.,  0.,  ...,  1., -1., -1.],\n",
      "        [-1., -1.,  0.,  ...,  1., -1.,  1.],\n",
      "        [ 0.,  0.,  0.,  ...,  1., -1.,  1.]])\n"
     ]
    }
   ],
   "source": [
    "#weights_updated = torch.zeros(model.rp_layer.weight.size())\n",
    "#weights_updated = model.rp_layer.weight.data.clone()    \n",
    "#weights_updated = binarize_hard(weights_updated)\n",
    "#weights_updated = binary_sparse_encode(weights_updated, 0.8)\n",
    "#make the binarize function bipolar\n",
    "#model.rp_layer.weight.data  = weights_updated.clone()\n",
    "print(\"Trained Weights\")\n",
    "print(model.rp_layer.weight.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[ 1.,  0.,  0.,  ...,  1.,  1.,  1.],\n",
      "        [ 0.,  0.,  1.,  ..., -1.,  1.,  1.],\n",
      "        [ 0.,  1., -1.,  ...,  1., -1., -1.],\n",
      "        ...,\n",
      "        [ 0.,  0.,  0.,  ...,  1., -1., -1.],\n",
      "        [-1., -1.,  0.,  ...,  1., -1.,  1.],\n",
      "        [ 0.,  0.,  0.,  ...,  1., -1.,  1.]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print(model.rp_layer.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[ 1.,  0.,  0.,  ...,  1.,  1.,  1.],\n",
      "        [ 0.,  0.,  1.,  ..., -1.,  1.,  1.],\n",
      "        [ 0.,  1., -1.,  ...,  1., -1., -1.],\n",
      "        ...,\n",
      "        [ 0.,  0.,  0.,  ...,  1., -1., -1.],\n",
      "        [-1., -1.,  0.,  ...,  1., -1.,  1.],\n",
      "        [ 0.,  0.,  0.,  ...,  1., -1.,  1.]], requires_grad=True)\n",
      "Epoch 1\n",
      "Epoch 2\n",
      "Epoch 3\n",
      "Epoch 4\n",
      "Epoch 5\n",
      "Epoch 6\n",
      "Epoch 7\n",
      "Epoch 8\n",
      "Epoch 9\n",
      "Epoch 10\n",
      "Epoch 11\n",
      "Epoch 12\n",
      "Epoch 13\n",
      "Epoch 14\n",
      "Epoch 15\n",
      "Epoch 16\n",
      "Epoch 17\n",
      "Epoch 18\n",
      "Epoch 19\n",
      "Epoch 20\n"
     ]
    }
   ],
   "source": [
    "num_HD_epoch = 20\n",
    "HD_lr = 0.1\n",
    "print(model.rp_layer.weight)\n",
    "for epoch_i in range(1, num_HD_epoch+1):\n",
    "    model.HD_train_step(x_train, y_train, lr=HD_lr)\n",
    "    accuracies.append(HD_test(model, x_test, y_test).item())\n",
    "    margins.append(get_Hamming_margin(model, x_test, y_test))\n",
    "    print(\"Epoch\",epoch_i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum Accuracy:0.9398000240325928\n",
      "Parameter containing:\n",
      "tensor([[ 1.,  0.,  0.,  ...,  1.,  1.,  1.],\n",
      "        [ 0.,  0.,  1.,  ..., -1.,  1.,  1.],\n",
      "        [ 0.,  1., -1.,  ...,  1., -1., -1.],\n",
      "        ...,\n",
      "        [ 0.,  0.,  0.,  ...,  1., -1., -1.],\n",
      "        [-1., -1.,  0.,  ...,  1., -1.,  1.],\n",
      "        [ 0.,  0.,  0.,  ...,  1., -1.,  1.]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "plt.plot(accuracies, label=\"Accuracy\", c = \"blue\")\n",
    "plt.xlabel(\"iterations\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.title(\"Accuracy of 2 Levels, 4000 Dimensions Dataset:mnist\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "print(\"Maximum Accuracy:{}\".format(max(accuracies)))\n",
    "torch.save(model, './model/model.pth')\n",
    "print(model.rp_layer.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[ 0.,  0., -1.,  ..., -1.,  1.,  1.],\n",
      "        [ 0.,  0.,  0.,  ..., -1., -1.,  1.],\n",
      "        [-1.,  0.,  0.,  ..., -1.,  1.,  1.],\n",
      "        ...,\n",
      "        [ 0.,  0.,  0.,  ...,  1., -1.,  1.],\n",
      "        [ 0.,  0.,  0.,  ...,  1.,  1., -1.],\n",
      "        [ 0.,  0.,  0.,  ...,  1.,  1., -1.]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print(model.rp_layer.weight)\n",
    "weight_array = model.rp_layer.weight.detach().numpy()\n",
    "#print(torch.tensor(weight_array, requires_grad=True))\n",
    "#print(weight_array == model.rp_layer.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gkpd import gkpd\n",
    "from gkpd.tensorops import kron\n",
    "class KroneckerDecomposition_new(nn.Module):\n",
    "        # def __init__(self, dim, D, num_classes, enc_type='RP', binary=True, device='cpu', kargs=None):\n",
    "        # super(BinaryModel, self).__init__()\n",
    "    def __init__(self,A,B, dim, D, num_classes,block_size,sparsity ):\n",
    "        super(KroneckerDecomposition_new, self).__init__()\n",
    "        self.A = torch.nn.Parameter(torch.tensor(A))\n",
    "        self.B = torch.nn.Parameter(torch.tensor(B))\n",
    "        #self.weight_kron = torch.nn.Parameter(self.weight_kron)\n",
    "        self.class_hvs = torch.zeros(num_classes, D).float().to(device)\n",
    "        self.class_hvs_nb = torch.zeros(num_classes, D).float().to(device)\n",
    "        self.sparsity = sparsity\n",
    "        self.block_size = block_size\n",
    "\n",
    "    def weight_binarize(self, W):\n",
    "       W = torch.where(W<-1,-1,W)\n",
    "       W = torch.where(W>1,1,W)\n",
    "       mask1 = (W >= -1) & (W < 0)\n",
    "       W[mask1] = 2 * W[mask1] + W[mask1]*W[mask1]\n",
    "       mask2 = (W >= 0) & (W < 1)\n",
    "       W[mask2] = 2 * W[mask2] - W[mask2]*W[mask2]\n",
    "       W = W.float()\n",
    "       return W\n",
    "        \n",
    "    def forward(self,x, embedding=False):\n",
    "        out = self.encoding(x)\n",
    "        if embedding:\n",
    "            out = out\n",
    "        else:\n",
    "            out = self.similarity(class_hvs=binarize_hard(self.class_hvs), enc_hv=out)   \n",
    "        return out\n",
    "    \n",
    "    def encoding(self,x):\n",
    "        #print(\"Entering Encoding\")\n",
    "        bin_A = self.weight_binarize(self.A)\n",
    "        bin_B = self.weight_binarize(self.B)\n",
    "        #below two lines for reference\n",
    "        #weight_sparse = obtain_sparsity(weights_bin, self.block_size,self.sparsity)\n",
    "        #self.rp_layer.weight.data = weight_sparse.clone()\n",
    "        #cyclic rotation to generate mask \n",
    "        #or some other predictable way to achieve \n",
    "        bin_A_sparse = obtain_sparsity(bin_A,self.block_size, self.sparsity)\n",
    "        bin_B_sparse = obtain_sparsity(bin_B,self.block_size, self.sparsity)\n",
    "        weight_kron = kron(bin_A_sparse, bin_B_sparse).clone()\n",
    "        weight_kron_size = list(weight_kron.size())\n",
    "        weight_kron = weight_kron.view(weight_kron_size[0],weight_kron_size[1]).clone()\n",
    "        #print(\"Finished reshape\")\n",
    "        out = torch.matmul(x,weight_kron.t())\n",
    "        #print(\"Encoding Done\")\n",
    "        return self.weight_binarize(out)\n",
    "    \n",
    "    def init_class(self, x_train, labels_train):\n",
    "        out = self.encoding(x_train)\n",
    "        for i in range(x_train.size()[0]):\n",
    "            self.class_hvs[labels_train[i]] += out[i]\n",
    "\n",
    "        self.class_hvs = binarize_hard(self.class_hvs)\n",
    "    \n",
    "    def HD_train_step(self, x_train, y_train, lr=1.0):\n",
    "        shuffle_idx = torch.randperm(x_train.size()[0])\n",
    "        x_train = x_train[shuffle_idx]\n",
    "        train_labels = y_train[shuffle_idx]\n",
    "        #l= list(self.rp_layer.parameters())\n",
    "        enc_hvs = binarize_hard(self.encoding(x_train))\n",
    "        for i in range(enc_hvs.size()[0]):\n",
    "            sims = self.similarity(self.class_hvs, enc_hvs[i].unsqueeze(dim=0))\n",
    "            predict = torch.argmax(sims, dim=1)\n",
    "            \n",
    "            if predict != train_labels[i]:\n",
    "                self.class_hvs_nb[predict] -= lr * enc_hvs[i]\n",
    "                self.class_hvs_nb[train_labels[i]] += lr * enc_hvs[i]\n",
    "            \n",
    "            self.class_hvs.data = binarize_hard(self.class_hvs_nb)\n",
    "    \n",
    "    def similarity(self, class_hvs, enc_hv):\n",
    "\t    return torch.matmul(enc_hv, class_hvs.t())/class_hvs.size()[1]\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "def  metric_train_svd (model, loss_func, mining_func, device, train_loader, optimizer):\n",
    "    model.train()\n",
    "    for batch_idx, (data, labels) in enumerate(train_loader):\n",
    "        data, labels = data.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        embeddings = model(data.reshape(data.size()[0],-1))\n",
    "        indices_tuple = mining_func(embeddings, labels)\n",
    "        loss = loss_func(embeddings,labels,indices_tuple)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reconstruction error: 0.0008\n",
      "tensor([[[[[ 5.3032e-01]],\n",
      "\n",
      "          [[-6.1224e-01]],\n",
      "\n",
      "          [[ 2.0136e-01]],\n",
      "\n",
      "          ...,\n",
      "\n",
      "          [[ 6.7715e+00]],\n",
      "\n",
      "          [[-2.8483e+00]],\n",
      "\n",
      "          [[ 1.1234e+01]]],\n",
      "\n",
      "\n",
      "         [[[-3.7892e-01]],\n",
      "\n",
      "          [[ 7.3485e-01]],\n",
      "\n",
      "          [[-6.6858e-01]],\n",
      "\n",
      "          ...,\n",
      "\n",
      "          [[ 2.2590e+00]],\n",
      "\n",
      "          [[ 7.4093e+00]],\n",
      "\n",
      "          [[ 2.2665e+00]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[-1.8133e-01]],\n",
      "\n",
      "          [[-3.2817e-02]],\n",
      "\n",
      "          [[ 6.3828e-01]],\n",
      "\n",
      "          ...,\n",
      "\n",
      "          [[-8.9608e+00]],\n",
      "\n",
      "          [[ 5.3748e+00]],\n",
      "\n",
      "          [[ 3.4480e+00]]],\n",
      "\n",
      "\n",
      "         [[[ 1.1231e+00]],\n",
      "\n",
      "          [[ 2.5481e-02]],\n",
      "\n",
      "          [[ 9.5050e-01]],\n",
      "\n",
      "          ...,\n",
      "\n",
      "          [[ 2.0505e+00]],\n",
      "\n",
      "          [[ 1.1202e+00]],\n",
      "\n",
      "          [[ 8.3296e+00]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[ 2.5427e-01]],\n",
      "\n",
      "          [[-6.7767e-01]],\n",
      "\n",
      "          [[ 1.9937e-01]],\n",
      "\n",
      "          ...,\n",
      "\n",
      "          [[-1.2730e+00]],\n",
      "\n",
      "          [[ 2.2601e+00]],\n",
      "\n",
      "          [[ 3.5722e+00]]],\n",
      "\n",
      "\n",
      "         [[[ 2.1938e-01]],\n",
      "\n",
      "          [[ 2.3824e-01]],\n",
      "\n",
      "          [[ 4.1175e-01]],\n",
      "\n",
      "          ...,\n",
      "\n",
      "          [[-1.2871e+00]],\n",
      "\n",
      "          [[ 3.8017e+00]],\n",
      "\n",
      "          [[-4.0818e+00]]]],\n",
      "\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "\n",
      "        [[[[-1.2422e-01]],\n",
      "\n",
      "          [[-3.8221e-02]],\n",
      "\n",
      "          [[-2.0140e-02]],\n",
      "\n",
      "          ...,\n",
      "\n",
      "          [[-2.1043e-03]],\n",
      "\n",
      "          [[-2.1567e-02]],\n",
      "\n",
      "          [[ 2.3499e-02]]],\n",
      "\n",
      "\n",
      "         [[[-7.4341e-02]],\n",
      "\n",
      "          [[ 4.1618e-02]],\n",
      "\n",
      "          [[-4.1635e-02]],\n",
      "\n",
      "          ...,\n",
      "\n",
      "          [[-3.4114e-02]],\n",
      "\n",
      "          [[ 4.9964e-03]],\n",
      "\n",
      "          [[ 1.1599e-02]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[ 4.1286e-02]],\n",
      "\n",
      "          [[ 1.4906e-01]],\n",
      "\n",
      "          [[ 1.0763e-01]],\n",
      "\n",
      "          ...,\n",
      "\n",
      "          [[-2.3602e-03]],\n",
      "\n",
      "          [[-1.8285e-02]],\n",
      "\n",
      "          [[-3.0471e-03]]],\n",
      "\n",
      "\n",
      "         [[[-1.5731e-01]],\n",
      "\n",
      "          [[ 1.3529e-01]],\n",
      "\n",
      "          [[-5.4351e-02]],\n",
      "\n",
      "          ...,\n",
      "\n",
      "          [[-5.9747e-02]],\n",
      "\n",
      "          [[-4.4365e-02]],\n",
      "\n",
      "          [[-3.0039e-02]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[-6.9509e-03]],\n",
      "\n",
      "          [[ 3.8514e-02]],\n",
      "\n",
      "          [[-3.7148e-02]],\n",
      "\n",
      "          ...,\n",
      "\n",
      "          [[-1.8087e-02]],\n",
      "\n",
      "          [[ 3.7887e-02]],\n",
      "\n",
      "          [[ 1.6959e-02]]],\n",
      "\n",
      "\n",
      "         [[[-1.3426e-01]],\n",
      "\n",
      "          [[-2.8807e-02]],\n",
      "\n",
      "          [[ 5.5315e-02]],\n",
      "\n",
      "          ...,\n",
      "\n",
      "          [[-1.4424e-02]],\n",
      "\n",
      "          [[-3.1050e-02]],\n",
      "\n",
      "          [[-1.1963e-02]]]]])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from gkpd import gkpd\n",
    "from gkpd.tensorops import kron\n",
    "from gkpd.tensorops import multidimensional_unfold\n",
    "\n",
    "w = model.rp_layer.weight\n",
    "w = w.view(1000,784,1,1)\n",
    "#print(w.shape)\n",
    "rank = 8\n",
    "a_shape, b_shape = (rank, 2, 392, 1, 1), (rank, 500, 2, 1, 1)\n",
    "#a, b = torch.randn(*a_shape), torch.randn(*b_shape)\n",
    "#w = kron(a, b)\n",
    "#print(w.shape)\n",
    "#print(a.shape)\n",
    "a_hat, b_hat = gkpd(w, a_shape[1:], b_shape[1:])\n",
    "w_hat = kron(a_hat, b_hat)\n",
    "\n",
    "    # Reconstruction error\n",
    "print(\"Reconstruction error: {}\".format(\n",
    "round((torch.linalg.norm((w.reshape(-1) - w_hat.reshape(-1))).detach().numpy()).item(), 4)\n",
    "))\n",
    "print(a_hat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([784, 2, 392, 1, 1])\n",
      "(2, 392)\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "tuple index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[174], line 10\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[39mprint\u001b[39m(a_shape)\n\u001b[0;32m      6\u001b[0m \u001b[39m# stride = 1\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[39m# stride = tuple(stride)\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[39m# print(stride)\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[39m#a_hat_sparse = obtain_sparsity(a_hat_binarize[1:],block_size=a_shape,)\u001b[39;00m\n\u001b[1;32m---> 10\u001b[0m a_hat_binarize_unfold \u001b[39m=\u001b[39m multidimensional_unfold(a_hat_binarize,a_shape,a_shape)\n\u001b[0;32m     11\u001b[0m \u001b[39m#print(a_hat_binarize_unfold.shape)\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Project Work\\RRAM-error-model-main\\RRAM-error-model-main\\gkpd\\tensorops.py:27\u001b[0m, in \u001b[0;36mmultidimensional_unfold\u001b[1;34m(tensor, kernel_size, stride, device)\u001b[0m\n\u001b[0;32m     24\u001b[0m s_dims \u001b[39m=\u001b[39m tensor\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m:]  \u001b[39m# spatial dimensions\u001b[39;00m\n\u001b[0;32m     26\u001b[0m \u001b[39m# Number of positions along each axis\u001b[39;00m\n\u001b[1;32m---> 27\u001b[0m num_positions \u001b[39m=\u001b[39m [np\u001b[39m.\u001b[39mfloor((s_dims[i] \u001b[39m-\u001b[39m (kernel_size[i] \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m) \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m) \u001b[39m/\u001b[39m stride[i] \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m)\u001b[39m.\u001b[39mastype(\u001b[39mint\u001b[39m)\n\u001b[0;32m     28\u001b[0m                  \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(s_dims))]\n\u001b[0;32m     30\u001b[0m \u001b[39m# Start indices for each position in each axis\u001b[39;00m\n\u001b[0;32m     31\u001b[0m positions \u001b[39m=\u001b[39m [torch\u001b[39m.\u001b[39mtensor([n \u001b[39m*\u001b[39m stride[i] \u001b[39mfor\u001b[39;00m n \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(num_positions[i] \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)]) \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m\n\u001b[0;32m     32\u001b[0m              \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(num_positions))]\n",
      "File \u001b[1;32mc:\\Project Work\\RRAM-error-model-main\\RRAM-error-model-main\\gkpd\\tensorops.py:27\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     24\u001b[0m s_dims \u001b[39m=\u001b[39m tensor\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m:]  \u001b[39m# spatial dimensions\u001b[39;00m\n\u001b[0;32m     26\u001b[0m \u001b[39m# Number of positions along each axis\u001b[39;00m\n\u001b[1;32m---> 27\u001b[0m num_positions \u001b[39m=\u001b[39m [np\u001b[39m.\u001b[39mfloor((s_dims[i] \u001b[39m-\u001b[39m (kernel_size[i] \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m) \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m) \u001b[39m/\u001b[39m stride[i] \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m)\u001b[39m.\u001b[39mastype(\u001b[39mint\u001b[39m)\n\u001b[0;32m     28\u001b[0m                  \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(s_dims))]\n\u001b[0;32m     30\u001b[0m \u001b[39m# Start indices for each position in each axis\u001b[39;00m\n\u001b[0;32m     31\u001b[0m positions \u001b[39m=\u001b[39m [torch\u001b[39m.\u001b[39mtensor([n \u001b[39m*\u001b[39m stride[i] \u001b[39mfor\u001b[39;00m n \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(num_positions[i] \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)]) \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m\n\u001b[0;32m     32\u001b[0m              \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(num_positions))]\n",
      "\u001b[1;31mIndexError\u001b[0m: tuple index out of range"
     ]
    }
   ],
   "source": [
    "\n",
    "a_hat_binarize = activation_binarize(a_hat)\n",
    "print(a_hat_binarize.shape)\n",
    "a_shape = a_hat_binarize.shape[1:3]\n",
    "a_shape = tuple(a_shape)\n",
    "print(a_shape)\n",
    "# stride = 1\n",
    "# stride = tuple(stride)\n",
    "# print(stride)\n",
    "#a_hat_sparse = obtain_sparsity(a_hat_binarize[1:],block_size=a_shape,)\n",
    "a_hat_binarize_unfold = multidimensional_unfold(a_hat_binarize,a_shape,a_shape)\n",
    "#print(a_hat_binarize_unfold.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "784 2 392 1 1\n",
      "torch.Size([784, 500, 2, 1, 1])\n",
      "torch.Size([1000, 784, 1, 1])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(*a_hat.shape)\n",
    "print(b_hat.shape)\n",
    "print(w_hat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Viji Swaminathan\\AppData\\Local\\Temp\\ipykernel_16804\\2526987213.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.A = torch.nn.Parameter(torch.tensor(A))\n",
      "C:\\Users\\Viji Swaminathan\\AppData\\Local\\Temp\\ipykernel_16804\\2526987213.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.B = torch.nn.Parameter(torch.tensor(B))\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "kthvalue(): selected number k out of range for dimension 3",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[158], line 8\u001b[0m\n\u001b[0;32m      6\u001b[0m kronecker_accuracies \u001b[39m=\u001b[39m []\n\u001b[0;32m      7\u001b[0m kronecker_margins \u001b[39m=\u001b[39m []\n\u001b[1;32m----> 8\u001b[0m kronecker_accuracies\u001b[39m.\u001b[39mappend(HD_test(kronecker_model, x_test, y_test)\u001b[39m.\u001b[39mitem())\n\u001b[0;32m      9\u001b[0m kronecker_margins\u001b[39m.\u001b[39mappend(get_Hamming_margin(kronecker_model, x_test, y_test))\n",
      "Cell \u001b[1;32mIn[94], line 2\u001b[0m, in \u001b[0;36mHD_test\u001b[1;34m(model, x_test, y_test)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mHD_test\u001b[39m(model, x_test, y_test):\n\u001b[1;32m----> 2\u001b[0m \tout \u001b[39m=\u001b[39m model(x_test, embedding\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[0;32m      3\u001b[0m \tpreds \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39margmax(out, dim\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m      4\u001b[0m \tacc \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mmean((preds\u001b[39m==\u001b[39my_test)\u001b[39m.\u001b[39mfloat())\t\n",
      "File \u001b[1;32mc:\\Users\\Viji Swaminathan\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "Cell \u001b[1;32mIn[157], line 27\u001b[0m, in \u001b[0;36mKroneckerDecomposition_new.forward\u001b[1;34m(self, x, embedding)\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m,x, embedding\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m):\n\u001b[1;32m---> 27\u001b[0m     out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mencoding(x)\n\u001b[0;32m     28\u001b[0m     \u001b[39mif\u001b[39;00m embedding:\n\u001b[0;32m     29\u001b[0m         out \u001b[39m=\u001b[39m out\n",
      "Cell \u001b[1;32mIn[157], line 42\u001b[0m, in \u001b[0;36mKroneckerDecomposition_new.encoding\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[39m#below two lines for reference\u001b[39;00m\n\u001b[0;32m     39\u001b[0m \u001b[39m#weight_sparse = obtain_sparsity(weights_bin, self.block_size,self.sparsity)\u001b[39;00m\n\u001b[0;32m     40\u001b[0m \u001b[39m#self.rp_layer.weight.data = weight_sparse.clone()\u001b[39;00m\n\u001b[0;32m     41\u001b[0m bin_A_sparse \u001b[39m=\u001b[39m obtain_sparsity(bin_A,\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mblock_size, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msparsity)\n\u001b[1;32m---> 42\u001b[0m bin_B_sparse \u001b[39m=\u001b[39m obtain_sparsity(bin_B,\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mblock_size, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msparsity)\n\u001b[0;32m     43\u001b[0m weight_kron \u001b[39m=\u001b[39m kron(bin_A_sparse, bin_B_sparse)\u001b[39m.\u001b[39mclone()\n\u001b[0;32m     44\u001b[0m weight_kron_size \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(weight_kron\u001b[39m.\u001b[39msize())\n",
      "Cell \u001b[1;32mIn[128], line 22\u001b[0m, in \u001b[0;36mobtain_sparsity\u001b[1;34m(w, block_size, sparsity)\u001b[0m\n\u001b[0;32m     20\u001b[0m block \u001b[39m=\u001b[39m w[j,i\u001b[39m*\u001b[39mblock_size:(i\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m)\u001b[39m*\u001b[39mblock_size]\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mclone()\n\u001b[0;32m     21\u001b[0m \u001b[39m#print(block)\u001b[39;00m\n\u001b[1;32m---> 22\u001b[0m block \u001b[39m=\u001b[39m binary_sparse_encode(block, sparsity) \n\u001b[0;32m     23\u001b[0m \u001b[39m# Add the block to the list of blocks\u001b[39;00m\n\u001b[0;32m     24\u001b[0m w[j,i\u001b[39m*\u001b[39mblock_size:(i\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m)\u001b[39m*\u001b[39mblock_size] \u001b[39m=\u001b[39m block\u001b[39m.\u001b[39mclone()\n",
      "Cell \u001b[1;32mIn[117], line 7\u001b[0m, in \u001b[0;36mbinary_sparse_encode\u001b[1;34m(w, sparsity)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mbinary_sparse_encode\u001b[39m(w, sparsity):\n\u001b[0;32m      2\u001b[0m     \u001b[39m# Flatten the weight tensor\u001b[39;00m\n\u001b[0;32m      3\u001b[0m     \u001b[39m#w_flat = w.reshape(-1)\u001b[39;00m\n\u001b[0;32m      4\u001b[0m     \u001b[39m#print(w.size())\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \n\u001b[0;32m      6\u001b[0m     \u001b[39m# Calculate the threshold value for sparsity\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m     threshold \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mkthvalue(torch\u001b[39m.\u001b[39;49mabs(w), \u001b[39mint\u001b[39;49m(sparsity \u001b[39m*\u001b[39;49m w\u001b[39m.\u001b[39;49mnumel()))\u001b[39m.\u001b[39mvalues\n\u001b[0;32m      9\u001b[0m     \u001b[39m# Apply binary sparse encoding\u001b[39;00m\n\u001b[0;32m     10\u001b[0m     w_sparse \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mwhere(torch\u001b[39m.\u001b[39mabs(w) \u001b[39m<\u001b[39m threshold, torch\u001b[39m.\u001b[39mtensor(\u001b[39m0.\u001b[39m), activation_binarize(w))\n",
      "\u001b[1;31mRuntimeError\u001b[0m: kthvalue(): selected number k out of range for dimension 3"
     ]
    }
   ],
   "source": [
    "kronecker_model = KroneckerDecomposition_new(A=a_hat,B=b_hat,dim = nFeatures, D=1000, num_classes=nClasses,block_size = 50, sparsity = 0.8)\n",
    "lr = 0.1\n",
    "loss_func = losses.TripletMarginLoss(margin=0.2, distance=distance, reducer=reducer)\n",
    "optimizer = optim.Adam(kronecker_model.parameters(), lr=lr, weight_decay=0) \n",
    "kronecker_model.class_hvs = nn.parameter.Parameter(data=kronecker_model.class_hvs)\n",
    "kronecker_accuracies = []\n",
    "kronecker_margins = []\n",
    "kronecker_accuracies.append(HD_test(kronecker_model, x_test, y_test).item())\n",
    "kronecker_margins.append(get_Hamming_margin(kronecker_model, x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Triplet Loss\n",
      "Metric train\n",
      "Finished binarizing\n",
      "Finished binarizing\n",
      "Finished binarizing\n",
      "Finished binarizing\n",
      "Finished binarizing\n",
      "Finished binarizing\n",
      "Finished binarizing\n",
      "Finished binarizing\n",
      "Finished binarizing\n",
      "Finished binarizing\n",
      "Finished binarizing\n",
      "Finished binarizing\n",
      "Finished binarizing\n",
      "Finished binarizing\n",
      "Finished binarizing\n",
      "Finished binarizing\n",
      "Finished binarizing\n",
      "Finished binarizing\n",
      "Finished binarizing\n",
      "Finished binarizing\n",
      "Finished binarizing\n",
      "Finished binarizing\n",
      "Finished binarizing\n",
      "Finished binarizing\n",
      "Finished binarizing\n",
      "Finished binarizing\n",
      "Finished binarizing\n",
      "Finished binarizing\n",
      "Finished binarizing\n",
      "Finished binarizing\n",
      "Finished binarizing\n",
      "Finished binarizing\n",
      "Finished binarizing\n",
      "Finished binarizing\n",
      "Finished binarizing\n",
      "Finished binarizing\n",
      "Finished binarizing\n",
      "Finished binarizing\n",
      "Finished binarizing\n",
      "Finished binarizing\n",
      "Finished binarizing\n",
      "Finished binarizing\n",
      "Finished binarizing\n",
      "Finished binarizing\n",
      "Finished binarizing\n",
      "Finished binarizing\n",
      "Finished binarizing\n",
      "Finished binarizing\n",
      "Finished binarizing\n",
      "Finished binarizing\n",
      "Finished binarizing\n",
      "Finished binarizing\n",
      "Finished binarizing\n",
      "Finished binarizing\n",
      "Finished binarizing\n",
      "Finished binarizing\n",
      "Finished binarizing\n",
      "Finished binarizing\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[90], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mTriplet Loss\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m      3\u001b[0m \u001b[39mfor\u001b[39;00m epoch_i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m1\u001b[39m, num_metric_epochs \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m):\n\u001b[1;32m----> 4\u001b[0m     metric_train_svd(kronecker_model, loss_func, mining_func, device, train_loader, optimizer)\n\u001b[0;32m      5\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mmetric_Train_done\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m      6\u001b[0m     kronecker_accuracies\u001b[39m.\u001b[39mappend(HD_test(kronecker_model, x_test, y_test)\u001b[39m.\u001b[39mitem())\n",
      "Cell \u001b[1;32mIn[84], line 7\u001b[0m, in \u001b[0;36mmetric_train_svd\u001b[1;34m(model, loss_func, mining_func, device, train_loader, optimizer)\u001b[0m\n\u001b[0;32m      5\u001b[0m data, labels \u001b[39m=\u001b[39m data\u001b[39m.\u001b[39mto(device), labels\u001b[39m.\u001b[39mto(device)\n\u001b[0;32m      6\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[1;32m----> 7\u001b[0m embeddings \u001b[39m=\u001b[39m model(data\u001b[39m.\u001b[39;49mreshape(data\u001b[39m.\u001b[39;49msize()[\u001b[39m0\u001b[39;49m],\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m))\n\u001b[0;32m      8\u001b[0m indices_tuple \u001b[39m=\u001b[39m mining_func(embeddings, labels)\n\u001b[0;32m      9\u001b[0m loss \u001b[39m=\u001b[39m loss_func(embeddings,labels,indices_tuple)\n",
      "File \u001b[1;32mc:\\Users\\Viji Swaminathan\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "Cell \u001b[1;32mIn[88], line 24\u001b[0m, in \u001b[0;36mKroneckerDecomposition_new.forward\u001b[1;34m(self, x, embedding)\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m,x, embedding\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m):\n\u001b[1;32m---> 24\u001b[0m     out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mencoding(x)\n\u001b[0;32m     25\u001b[0m     \u001b[39mif\u001b[39;00m embedding:\n\u001b[0;32m     26\u001b[0m         out \u001b[39m=\u001b[39m out\n",
      "Cell \u001b[1;32mIn[88], line 36\u001b[0m, in \u001b[0;36mKroneckerDecomposition_new.encoding\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     34\u001b[0m bin_B \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mweight_binarize(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mB)\n\u001b[0;32m     35\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mFinished binarizing\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m---> 36\u001b[0m weight_kron \u001b[39m=\u001b[39m kron(bin_A, bin_B)\n\u001b[0;32m     37\u001b[0m \u001b[39m#print(\"Finished kron\")\u001b[39;00m\n\u001b[0;32m     38\u001b[0m weight_kron_size \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(weight_kron\u001b[39m.\u001b[39msize())\n",
      "File \u001b[1;32mc:\\Project Work\\RRAM-error-model-main\\RRAM-error-model-main\\gkpd\\tensorops.py:75\u001b[0m, in \u001b[0;36mkron\u001b[1;34m(a, b)\u001b[0m\n\u001b[0;32m     72\u001b[0m a \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mfrom_numpy(a) \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(a, np\u001b[39m.\u001b[39mndarray) \u001b[39melse\u001b[39;00m a\n\u001b[0;32m     73\u001b[0m b \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mfrom_numpy(b) \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(b, np\u001b[39m.\u001b[39mndarray) \u001b[39melse\u001b[39;00m b\n\u001b[1;32m---> 75\u001b[0m \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39mstack([torch\u001b[39m.\u001b[39mkron(a[k], b[k]) \u001b[39mfor\u001b[39;00m k \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(a\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m])])\u001b[39m.\u001b[39msum(dim\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n",
      "File \u001b[1;32mc:\\Project Work\\RRAM-error-model-main\\RRAM-error-model-main\\gkpd\\tensorops.py:75\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     72\u001b[0m a \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mfrom_numpy(a) \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(a, np\u001b[39m.\u001b[39mndarray) \u001b[39melse\u001b[39;00m a\n\u001b[0;32m     73\u001b[0m b \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mfrom_numpy(b) \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(b, np\u001b[39m.\u001b[39mndarray) \u001b[39melse\u001b[39;00m b\n\u001b[1;32m---> 75\u001b[0m \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39mstack([torch\u001b[39m.\u001b[39;49mkron(a[k], b[k]) \u001b[39mfor\u001b[39;00m k \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(a\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m])])\u001b[39m.\u001b[39msum(dim\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "num_metric_epochs = 1\n",
    "print(\"Triplet Loss\")\n",
    "for epoch_i in range(1, num_metric_epochs + 1):\n",
    "    metric_train_svd(kronecker_model, loss_func, mining_func, device, train_loader, optimizer)\n",
    "    print(\"metric_Train_done\")\n",
    "    kronecker_accuracies.append(HD_test(kronecker_model, x_test, y_test).item())\n",
    "    print(\"accuracies done\")\n",
    "    kronecker_margins.append(get_Hamming_margin(kronecker_model, x_test, y_test))\n",
    "    print(\"margins done\")\n",
    "    print(\"Epoch\",epoch_i)\n",
    "    print(\"Accuracies\",HD_test(kronecker_model, x_test, y_test).item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[[[[ 1.]],\n",
      "\n",
      "          [[-1.]],\n",
      "\n",
      "          [[ 1.]],\n",
      "\n",
      "          ...,\n",
      "\n",
      "          [[ 1.]],\n",
      "\n",
      "          [[-1.]],\n",
      "\n",
      "          [[-1.]]],\n",
      "\n",
      "\n",
      "         [[[ 1.]],\n",
      "\n",
      "          [[ 1.]],\n",
      "\n",
      "          [[-1.]],\n",
      "\n",
      "          ...,\n",
      "\n",
      "          [[ 1.]],\n",
      "\n",
      "          [[ 1.]],\n",
      "\n",
      "          [[-1.]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[-1.]],\n",
      "\n",
      "          [[ 1.]],\n",
      "\n",
      "          [[ 1.]],\n",
      "\n",
      "          ...,\n",
      "\n",
      "          [[-1.]],\n",
      "\n",
      "          [[ 1.]],\n",
      "\n",
      "          [[ 1.]]],\n",
      "\n",
      "\n",
      "         [[[-1.]],\n",
      "\n",
      "          [[-1.]],\n",
      "\n",
      "          [[ 1.]],\n",
      "\n",
      "          ...,\n",
      "\n",
      "          [[ 1.]],\n",
      "\n",
      "          [[-1.]],\n",
      "\n",
      "          [[ 1.]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[ 1.]],\n",
      "\n",
      "          [[-1.]],\n",
      "\n",
      "          [[ 1.]],\n",
      "\n",
      "          ...,\n",
      "\n",
      "          [[ 1.]],\n",
      "\n",
      "          [[-1.]],\n",
      "\n",
      "          [[-1.]]],\n",
      "\n",
      "\n",
      "         [[[-1.]],\n",
      "\n",
      "          [[-1.]],\n",
      "\n",
      "          [[-1.]],\n",
      "\n",
      "          ...,\n",
      "\n",
      "          [[-1.]],\n",
      "\n",
      "          [[-1.]],\n",
      "\n",
      "          [[ 1.]]]],\n",
      "\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "\n",
      "        [[[[-1.]],\n",
      "\n",
      "          [[ 1.]],\n",
      "\n",
      "          [[ 1.]],\n",
      "\n",
      "          ...,\n",
      "\n",
      "          [[-1.]],\n",
      "\n",
      "          [[-1.]],\n",
      "\n",
      "          [[-1.]]],\n",
      "\n",
      "\n",
      "         [[[ 1.]],\n",
      "\n",
      "          [[-1.]],\n",
      "\n",
      "          [[ 1.]],\n",
      "\n",
      "          ...,\n",
      "\n",
      "          [[-1.]],\n",
      "\n",
      "          [[-1.]],\n",
      "\n",
      "          [[-1.]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[ 1.]],\n",
      "\n",
      "          [[-1.]],\n",
      "\n",
      "          [[ 1.]],\n",
      "\n",
      "          ...,\n",
      "\n",
      "          [[ 1.]],\n",
      "\n",
      "          [[-1.]],\n",
      "\n",
      "          [[-1.]]],\n",
      "\n",
      "\n",
      "         [[[ 1.]],\n",
      "\n",
      "          [[-1.]],\n",
      "\n",
      "          [[-1.]],\n",
      "\n",
      "          ...,\n",
      "\n",
      "          [[ 1.]],\n",
      "\n",
      "          [[ 1.]],\n",
      "\n",
      "          [[ 1.]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[-1.]],\n",
      "\n",
      "          [[-1.]],\n",
      "\n",
      "          [[ 1.]],\n",
      "\n",
      "          ...,\n",
      "\n",
      "          [[-1.]],\n",
      "\n",
      "          [[ 1.]],\n",
      "\n",
      "          [[ 1.]]],\n",
      "\n",
      "\n",
      "         [[[-1.]],\n",
      "\n",
      "          [[ 1.]],\n",
      "\n",
      "          [[-1.]],\n",
      "\n",
      "          ...,\n",
      "\n",
      "          [[-1.]],\n",
      "\n",
      "          [[-1.]],\n",
      "\n",
      "          [[-1.]]]]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[[[[-1.]],\n",
      "\n",
      "          [[ 1.]]],\n",
      "\n",
      "\n",
      "         [[[ 1.]],\n",
      "\n",
      "          [[ 1.]]],\n",
      "\n",
      "\n",
      "         [[[-1.]],\n",
      "\n",
      "          [[-1.]]],\n",
      "\n",
      "\n",
      "         ...,\n",
      "\n",
      "\n",
      "         [[[ 1.]],\n",
      "\n",
      "          [[ 1.]]],\n",
      "\n",
      "\n",
      "         [[[ 1.]],\n",
      "\n",
      "          [[ 1.]]],\n",
      "\n",
      "\n",
      "         [[[-1.]],\n",
      "\n",
      "          [[ 1.]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[-1.]],\n",
      "\n",
      "          [[-1.]]],\n",
      "\n",
      "\n",
      "         [[[-1.]],\n",
      "\n",
      "          [[-1.]]],\n",
      "\n",
      "\n",
      "         [[[-1.]],\n",
      "\n",
      "          [[-1.]]],\n",
      "\n",
      "\n",
      "         ...,\n",
      "\n",
      "\n",
      "         [[[-1.]],\n",
      "\n",
      "          [[-1.]]],\n",
      "\n",
      "\n",
      "         [[[-1.]],\n",
      "\n",
      "          [[-1.]]],\n",
      "\n",
      "\n",
      "         [[[-1.]],\n",
      "\n",
      "          [[-1.]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[ 1.]],\n",
      "\n",
      "          [[-1.]]],\n",
      "\n",
      "\n",
      "         [[[ 1.]],\n",
      "\n",
      "          [[ 1.]]],\n",
      "\n",
      "\n",
      "         [[[-1.]],\n",
      "\n",
      "          [[-1.]]],\n",
      "\n",
      "\n",
      "         ...,\n",
      "\n",
      "\n",
      "         [[[ 1.]],\n",
      "\n",
      "          [[ 1.]]],\n",
      "\n",
      "\n",
      "         [[[ 1.]],\n",
      "\n",
      "          [[ 1.]]],\n",
      "\n",
      "\n",
      "         [[[ 1.]],\n",
      "\n",
      "          [[-1.]]]],\n",
      "\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "\n",
      "        [[[[-1.]],\n",
      "\n",
      "          [[-1.]]],\n",
      "\n",
      "\n",
      "         [[[ 1.]],\n",
      "\n",
      "          [[ 1.]]],\n",
      "\n",
      "\n",
      "         [[[ 1.]],\n",
      "\n",
      "          [[ 1.]]],\n",
      "\n",
      "\n",
      "         ...,\n",
      "\n",
      "\n",
      "         [[[ 1.]],\n",
      "\n",
      "          [[ 1.]]],\n",
      "\n",
      "\n",
      "         [[[-1.]],\n",
      "\n",
      "          [[-1.]]],\n",
      "\n",
      "\n",
      "         [[[ 1.]],\n",
      "\n",
      "          [[ 1.]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[ 1.]],\n",
      "\n",
      "          [[ 1.]]],\n",
      "\n",
      "\n",
      "         [[[-1.]],\n",
      "\n",
      "          [[-1.]]],\n",
      "\n",
      "\n",
      "         [[[-1.]],\n",
      "\n",
      "          [[-1.]]],\n",
      "\n",
      "\n",
      "         ...,\n",
      "\n",
      "\n",
      "         [[[ 1.]],\n",
      "\n",
      "          [[-1.]]],\n",
      "\n",
      "\n",
      "         [[[ 1.]],\n",
      "\n",
      "          [[ 1.]]],\n",
      "\n",
      "\n",
      "         [[[-1.]],\n",
      "\n",
      "          [[-1.]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[-1.]],\n",
      "\n",
      "          [[-1.]]],\n",
      "\n",
      "\n",
      "         [[[-1.]],\n",
      "\n",
      "          [[-1.]]],\n",
      "\n",
      "\n",
      "         [[[-1.]],\n",
      "\n",
      "          [[-1.]]],\n",
      "\n",
      "\n",
      "         ...,\n",
      "\n",
      "\n",
      "         [[[-1.]],\n",
      "\n",
      "          [[-1.]]],\n",
      "\n",
      "\n",
      "         [[[ 1.]],\n",
      "\n",
      "          [[ 1.]]],\n",
      "\n",
      "\n",
      "         [[[-1.]],\n",
      "\n",
      "          [[-1.]]]]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "A_updated = torch.zeros(kronecker_model.A.size())\n",
    "A_updated = kronecker_model.A.clone()    \n",
    "A_updated = binarize_hard(A_updated)\n",
    "kronecker_model.A.data = A_updated.clone()\n",
    "print(kronecker_model.A)\n",
    "B_updated = torch.zeros(kronecker_model.B.size())\n",
    "B_updated = kronecker_model.B.clone()    \n",
    "B_updated = binarize_hard(B_updated)\n",
    "kronecker_model.B.data = B_updated.clone()\n",
    "print(kronecker_model.B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished binarizing\n",
      "Finished binarizing\n",
      "Finished binarizing\n",
      "Finished binarizing\n",
      "Finished binarizing\n",
      "Finished binarizing\n",
      "Finished binarizing\n",
      "Finished binarizing\n",
      "Finished binarizing\n",
      "Finished binarizing\n"
     ]
    }
   ],
   "source": [
    "num_HD_epoch = 5\n",
    "\n",
    "for epoch_i in range(1, num_HD_epoch+1):\n",
    "    kronecker_model.HD_train_step(x_train, y_train, lr=HD_lr)\n",
    "    accuracies.append(HD_test(kronecker_model, x_test, y_test).item())\n",
    "    margins.append(get_Hamming_margin(kronecker_model, x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(accuracies, label=\"Accuracy\", c = \"blue\")\n",
    "plt.xlabel(\"iterations\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.title(\"Accuracy of 2 Levels, 1000 Dimensions Dataset:mnist\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "print(\"Maximum Accuracy:{}\".format(max(accuracies)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
